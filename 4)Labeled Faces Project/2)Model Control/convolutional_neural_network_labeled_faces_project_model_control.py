# -*- coding: utf-8 -*-
"""Convolutional Neural Network-Labeled Faces Project-Model Control.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nr4jW1sYrOpbY56X1JH2f6fnAJVsFwe7
"""

#Burada Yüz Tanıma Amaçlı Eğittiğimiz CNN Modelini Test Edeceğiz

from google.colab import files

# .h5 dosyasını bilgisayarından seçip yükle
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()  # .zip olarak yükle

import zipfile
import os

zip_path = "/content/lfw-deepfunneled.zip"  #veri setini zipten çıkarma
extract_path = "/content/lfw-deepfunneled"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("Veri seti çıkarıldı.")

#klasörü olan kişilerin adlarını alabilmek için kopyalama
import shutil

kaynak_dizin="/content/lfw-deepfunneled/lfw-deepfunneled"
hedef_dizin="/content/filtered_face"

if not os.path.exists(hedef_dizin):
  os.makedirs(hedef_dizin)

filtrelenen_kisiler = []

for kisi in os.listdir(kaynak_dizin):
  kisi_klasor= os.path.join(kaynak_dizin,kisi)

  if os.path.isdir(kisi_klasor):
    resimler = os.listdir(kisi_klasor)

    if( len(resimler)>=15):
      filtrelenen_kisiler.append(kisi)
      shutil.copytree(kisi_klasor,os.path.join(hedef_dizin,kisi))


print(f"Yeni kişi sayısı /15+ görsele sahip: {len(filtrelenen_kisiler)}")
print("Örnek Kişiler",filtrelenen_kisiler[:5])

import os
print(os.listdir("/content"))

#her kişinin bilgilerini ayırma

import os, shutil
from sklearn.model_selection import train_test_split

ana_dizin = "/content/filtered_face/lfw-deepfunneled"  # Gerçek kişi klasörlerinin olduğu dizin
hedef_dizin = "/content/data_split"
train_klasoru = os.path.join(hedef_dizin, "train")
test_klasoru = os.path.join(hedef_dizin, "test")

# Varsa temizleme
if os.path.exists(hedef_dizin):
    shutil.rmtree(hedef_dizin)

os.makedirs(train_klasoru)
os.makedirs(test_klasoru)

# Her kişi klasörü için işlem yapma
for kisi in os.listdir(ana_dizin):
    kisi_dizin = os.path.join(ana_dizin, kisi)
    if not os.path.isdir(kisi_dizin):
        continue

    resimler = os.listdir(kisi_dizin)
    if len(resimler) < 15:
        continue

    train_resimler, test_resimler = train_test_split(resimler, test_size=0.2, random_state=42)

    os.makedirs(os.path.join(train_klasoru, kisi))
    os.makedirs(os.path.join(test_klasoru, kisi))

    for resim in train_resimler:
        kaynak_yol = os.path.join(kisi_dizin, resim)
        hedef_yol = os.path.join(train_klasoru, kisi, resim)
        shutil.copy(kaynak_yol, hedef_yol)

    for resim in test_resimler:
        kaynak_yol = os.path.join(kisi_dizin, resim)
        hedef_yol = os.path.join(test_klasoru, kisi, resim)
        shutil.copy(kaynak_yol, hedef_yol)

print(" Eğitim ve test verisi başarıyla ayrıldı.")

print(os.listdir("/content/data_split/train")[:5])

from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(rescale=1./255)
train_gen = datagen.flow_from_directory(
    "/content/data_split/train",
    target_size=(100, 100),
    batch_size=32,
    class_mode='categorical'
)

# Sınıf adlarını kontrol edelim
print(train_gen.class_indices)

import json

with open("class_indices.json", "w") as f:
    json.dump(train_gen.class_indices, f)

from google.colab import files
files.download("class_indices.json")

#Modeli test etme
import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing import image
import json
import os

# Modeli yükle
model = tf.keras.models.load_model("lfw_yuz_tanima_modeli.h5")

# class_indices'i yükle
with open("class_indices.json", "r") as f:
    class_indices = json.load(f)

# id → etiket dönüşümü
class_labels = {v: k for k, v in class_indices.items()}

#test Klasöründen Örnek Görsel Yükleyip Tahmin Etme
import matplotlib.pyplot as plt


ornek_kisi = "Abdullah_Gul"
ornek_gorsel=os.path.join("data_split/test",ornek_kisi,os.listdir(os.path.join("data_split/test",ornek_kisi))[0])


#Görselin yüklenmesi ve önişleme

img=image.load_img(ornek_gorsel, target_size=(100,100))

img_array= image.img_to_array(img)

img_array= img_array/255.0#normalizasyon
img_array = np.expand_dims(img_array,axis=0)


tahmin= model.predict(img_array)
tahmin_sinif=np.argmax(tahmin)

print("Gerçek kişi",ornek_kisi)
print("Tahmin edilen kişi:", class_labels[tahmin_sinif])


plt.imshow(img)
plt.title(f"Tahmin: {class_labels[tahmin_sinif]}")
plt.axis("off")
plt.show()