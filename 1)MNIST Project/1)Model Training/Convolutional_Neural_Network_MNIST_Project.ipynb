{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "DWpdihBtJgdS",
        "outputId": "bfeefbb9-a7c1-45c7-9126-08c3a18c3676"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n--->CNN genellikle görsel veriler(resimler) üzerinde çalışan derin\\nöğrenme mimarisidir\\n\\n--->Görsel tanıma,yüz tanıma,el yazısı tanıma,medkal görüntü\\nsınıflandırma, trafik levhası okuma, nesne tespiti gibi alnlarda \\noldukça etkilidir.\\n\\n\\n     Geleneksel NN                     CNN\\n-------------------------------------------------------------    \\n                           | \\n-->Tüm piksel verileri     | -->Görseldeki örüntüler(kenar,şekil,\\ndoğrudan alır              | doku) algılar.\\n                           |\\n-->Çok fazla paramtre      | -->Parametre  paylaşımı ile daha az \\ngerekir                    |  ağırlık öğrenir.\\n                           |\\n-->Görsel verilerde        | -->Görsel verileri uzamsal (spatial)\\nyetersiz kalır             | ilişkileri öğrenir.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#CNN Convolutional Neural Network\n",
        "\n",
        "\"\"\"\n",
        "--->CNN genellikle görsel veriler(resimler) üzerinde çalışan derin\n",
        "öğrenme mimarisidir\n",
        "\n",
        "--->Görsel tanıma,yüz tanıma,el yazısı tanıma,medkal görüntü\n",
        "sınıflandırma, trafik levhası okuma, nesne tespiti gibi alnlarda\n",
        "oldukça etkilidir.\n",
        "\n",
        "\n",
        "     Geleneksel NN                     CNN\n",
        "-------------------------------------------------------------\n",
        "                           |\n",
        "-->Tüm piksel verileri     | -->Görseldeki örüntüler(kenar,şekil,\n",
        "doğrudan alır              | doku) algılar.\n",
        "                           |\n",
        "-->Çok fazla paramtre      | -->Parametre  paylaşımı ile daha az\n",
        "gerekir                    |  ağırlık öğrenir.\n",
        "                           |\n",
        "-->Görsel verilerde        | -->Görsel verileri uzamsal (spatial)\n",
        "yetersiz kalır             | ilişkileri öğrenir.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN KATMANLARI\n",
        "\n",
        "\"\"\"\n",
        "1)Convolutional Layer\n",
        "\n",
        "--->Görsellerin üzerinden filtre (kernel) geçirerek\n",
        "kenar, doku gibi özellikleri çıkarır\n",
        "\n",
        "--->Örneğin 3x3 filtre ile 28x28 resmi tarar ->yeni bir\n",
        "özellik haritasu üretir.\n",
        "\n",
        "--->Öğrenilen filtreler resimdeki önemli bölgelere odaklanır.\n",
        "\n",
        "\n",
        "2)ReLU(Activation)\n",
        "\n",
        "--->Negatif değerleri sıfırlar, doğruasal olmayan yapıları\n",
        "öğrenmesini sağlar.\n",
        "\n",
        "\n",
        "4)Pooling Layer(Genellikle MaxPooling)\n",
        "\n",
        "--->Resmin boyutunu küçültür,öenmli bilgileri tutar.\n",
        "\n",
        "--->Örneğin 2x2 alanda en büyük değerleri alır.\n",
        "(daha az hesaplama,daha az overfitting riski)\n",
        "\n",
        "\n",
        "5)Flatten Layer\n",
        "\n",
        "--->2D(matris) veriyi 1D vektöre çevirir.Dense katmanına\n",
        "hazırlık yapar.\n",
        "\n",
        "6)Dense Layer\n",
        "\n",
        "--->Klasik yapay sinir ağıdır.\n",
        "\n",
        "--->Son katmanda softmax ile sınıf tahmini yapılır.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "6xn_aqm6LTgE",
        "outputId": "3f25e99e-1f93-49be-9b58-bc7dc359caea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1)Convolutional Layer\\n\\n--->Görsellerin üzerinden filtre (kernel) geçirerek\\nkenar, doku gibi özellikleri çıkarır\\n\\n--->Örneğin 3x3 filtre ile 28x28 resmi tarar ->yeni bir\\nözellik haritasu üretir.\\n\\n--->Öğrenilen filtreler resimdeki önemli bölgelere odaklanır.\\n \\n\\n2)ReLU(Activation)\\n\\n--->Negatif değerleri sıfırlar, doğruasal olmayan yapıları\\nöğrenmesini sağlar.\\n\\n\\n4)Pooling Layer(Genellikle MaxPooling)\\n\\n--->Resmin boyutunu küçültür,öenmli bilgileri tutar.\\n\\n--->Örneğin 2x2 alanda en büyük değerleri alır.\\n(daha az hesaplama,daha az overfitting riski)\\n\\n\\n5)Flatten Layer\\n\\n--->2D(matris) veriyi 1D vektöre çevirir.Dense katmanına\\nhazırlık yapar.\\n\\n6)Dense Layer\\n\\n--->Klasik yapay sinir ağıdır.\\n\\n--->Son katmanda softmax ile sınıf tahmini yapılır.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MNIST veri seti ile el yazısını tanıma modeli kurma\n",
        "#CNN ile\n",
        "\n",
        "import tensorflow as tf\n",
        "#derin öğrenme için gerekli kütüphaneler\n",
        "from tensorflow.keras.datasets import mnist\n",
        "#Mnist veri setini yüklemek için\n",
        "\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "#model oluşturma ve yükleme için\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "#CNN katmanları için\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#etiketleri one-hot encode etmek için\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#görselleştirme için\n",
        "import numpy as np\n",
        "#sayısal işlemler için"
      ],
      "metadata": {
        "id": "doYppfVgM3y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VERİ YÜKLEME ve İNCELEME\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "#MNIST veri setini yüklüyoruz  dışarıdan dosyayla almamıza gerek\n",
        "#yok   28x28 boyutlarında el yazısı rakamlar\n",
        "\n",
        "print(\"Eğitim verisi boyutu:\",x_train.shape)\n",
        "print(\"Test verisi boyutu:\",x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcHLz-z0Ny9w",
        "outputId": "58012818-5a07-4e97-e109-7d80bc23e589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Eğitim verisi boyutu: (60000, 28, 28)\n",
            "Test verisi boyutu: (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "x_train: Görseller (60000 tane 28x28)\n",
        "\n",
        "y_train: Etiketler (0–9 arası rakamlar)\n",
        "\n",
        "x_test, y_test: 10000 tane test verisi\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wEYTdI5DOPge",
        "outputId": "f5cdd10d-04cb-424b-e1d7-8256f93e529a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nx_train: Görseller (60000 tane 28x28)\\n\\ny_train: Etiketler (0–9 arası rakamlar)\\n\\nx_test, y_test: 10000 tane test verisi\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GÖRSELİ ÖNİŞLEME (NORMALİZE EDİP ŞEKLİ DÖNÜŞTÜRMEK)\n",
        "\n",
        "x_train=x_train/255.0# pixel değerleri 0-255 arasındaki 0-1 arasına normalize\n",
        "#ediyoruz\n",
        "\n",
        "x_test = x_test/255.0\n",
        "\n",
        "x_train = x_train.reshape(-1,28,28,1)\n",
        "x_test = x_test.reshape(-1,28,28,1)\n",
        "\"\"\"\n",
        "CNN modeli paramtre olarak\n",
        "\n",
        "genişlik\n",
        "yükseklik\n",
        "kanal boyut bekler bunları atıyoruz\n",
        "\n",
        "MNIST siyah-beyaz kanal=1\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train,10)\n",
        "y_test= to_categorical(y_test, 10)\n",
        "#etiketleri one-hot encode yapma\n"
      ],
      "metadata": {
        "id": "Br3S6y3pOU7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN MODELİNİ OLUŞTURMA\n",
        "\n",
        "model = Sequential()\n",
        "#model katman katman oluşcak\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "#1. katman 32 filtre,3x3 boyutunda, aktivasyon fonksiyonu ise relu\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#2.katman Maxpooling ile görüntüüuü 2x2 lik alanda küçültme\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
        "#3. katman 64 filtreli başka bir convulation\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#4. katman tekrara maxpooling uygulama\n",
        "\n",
        "model.add(Flatten())\n",
        "#2D veriyi 1D halline getirir(yoğun katmana hazırlık)\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "#Dense(Tam Bağlantılı ) katman 12 nörün aktivasyon ReLU\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "#çıkış katmanı 10 sınıf(0-9 rakamları için) softmax ile olasılık verilir\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mmavzalfSIwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MODELİN DERLENMESİ\n",
        "\n",
        "#model derlemede optimzier,loss fonksiyonları ve başarı metriği tanımlanır\n",
        "model.compile(\n",
        "    optimizer='adam',  # ağırlıkları optimize eder\n",
        "    loss='categorical_crossentropy', # Öok sınıflı sınıflandırma için uygun\n",
        "    metrics=['accuracy'] # Doğruluk oranını ölçer\n",
        ")"
      ],
      "metadata": {
        "id": "56N_SQesTw43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL EĞİTMİ\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_data=(x_test, y_test))\n",
        "\n",
        "#Modeli eğitme 5 apıchs boyunca her seferinde 128 veri ile eğitilcek"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxVbbMolUPX6",
        "outputId": "88c31a5c-4b94-40cc-b9ce-651d60d23b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 111ms/step - accuracy: 0.8628 - loss: 0.4798 - val_accuracy: 0.9824 - val_loss: 0.0581\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 98ms/step - accuracy: 0.9826 - loss: 0.0574 - val_accuracy: 0.9852 - val_loss: 0.0469\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 98ms/step - accuracy: 0.9876 - loss: 0.0387 - val_accuracy: 0.9890 - val_loss: 0.0338\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 102ms/step - accuracy: 0.9913 - loss: 0.0282 - val_accuracy: 0.9898 - val_loss: 0.0315\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 98ms/step - accuracy: 0.9927 - loss: 0.0231 - val_accuracy: 0.9905 - val_loss: 0.0294\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d92fe83d410>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"el_yazisi_modeli.h5\")\n",
        "print(\"Model başarıyla kaydedildi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LilBBeQOV_Ty",
        "outputId": "dab9c71c-70b0-4b24-da81-83044b88d242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model başarıyla kaydedildi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"el_yazisi_modeli.h5\")\n",
        "#modeli indirme"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gBqKEyGHXSeB",
        "outputId": "e913f1fa-cd77-4f87-8f33-80440a5053cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e8130423-ee7c-4454-9635-dab3432f4994\", \"el_yazisi_modeli.h5\", 2740168)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}