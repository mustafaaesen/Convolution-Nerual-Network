# -*- coding: utf-8 -*-
"""Convolutional Neural Network-MNIST Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fOjy8tC2LuUiEDdvOn36fv392PsFKmkb
"""

#CNN Convolutional Neural Network

"""
--->CNN genellikle görsel veriler(resimler) üzerinde çalışan derin
öğrenme mimarisidir

--->Görsel tanıma,yüz tanıma,el yazısı tanıma,medkal görüntü
sınıflandırma, trafik levhası okuma, nesne tespiti gibi alnlarda
oldukça etkilidir.


     Geleneksel NN                     CNN
-------------------------------------------------------------
                           |
-->Tüm piksel verileri     | -->Görseldeki örüntüler(kenar,şekil,
doğrudan alır              | doku) algılar.
                           |
-->Çok fazla paramtre      | -->Parametre  paylaşımı ile daha az
gerekir                    |  ağırlık öğrenir.
                           |
-->Görsel verilerde        | -->Görsel verileri uzamsal (spatial)
yetersiz kalır             | ilişkileri öğrenir.

"""

#CNN KATMANLARI

"""
1)Convolutional Layer

--->Görsellerin üzerinden filtre (kernel) geçirerek
kenar, doku gibi özellikleri çıkarır

--->Örneğin 3x3 filtre ile 28x28 resmi tarar ->yeni bir
özellik haritasu üretir.

--->Öğrenilen filtreler resimdeki önemli bölgelere odaklanır.


2)ReLU(Activation)

--->Negatif değerleri sıfırlar, doğruasal olmayan yapıları
öğrenmesini sağlar.


4)Pooling Layer(Genellikle MaxPooling)

--->Resmin boyutunu küçültür,öenmli bilgileri tutar.

--->Örneğin 2x2 alanda en büyük değerleri alır.
(daha az hesaplama,daha az overfitting riski)


5)Flatten Layer

--->2D(matris) veriyi 1D vektöre çevirir.Dense katmanına
hazırlık yapar.

6)Dense Layer

--->Klasik yapay sinir ağıdır.

--->Son katmanda softmax ile sınıf tahmini yapılır.
"""

#MNIST veri seti ile el yazısını tanıma modeli kurma
#CNN ile

import tensorflow as tf
#derin öğrenme için gerekli kütüphaneler
from tensorflow.keras.datasets import mnist
#Mnist veri setini yüklemek için

from tensorflow.keras.models import Sequential, load_model
#model oluşturma ve yükleme için

from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
#CNN katmanları için

from tensorflow.keras.utils import to_categorical
#etiketleri one-hot encode etmek için

import matplotlib.pyplot as plt
#görselleştirme için
import numpy as np
#sayısal işlemler için

#VERİ YÜKLEME ve İNCELEME

(x_train, y_train),(x_test, y_test) = mnist.load_data()
#MNIST veri setini yüklüyoruz  dışarıdan dosyayla almamıza gerek
#yok   28x28 boyutlarında el yazısı rakamlar

print("Eğitim verisi boyutu:",x_train.shape)
print("Test verisi boyutu:",x_test.shape)

"""
x_train: Görseller (60000 tane 28x28)

y_train: Etiketler (0–9 arası rakamlar)

x_test, y_test: 10000 tane test verisi

"""

#GÖRSELİ ÖNİŞLEME (NORMALİZE EDİP ŞEKLİ DÖNÜŞTÜRMEK)

x_train=x_train/255.0# pixel değerleri 0-255 arasındaki 0-1 arasına normalize
#ediyoruz

x_test = x_test/255.0

x_train = x_train.reshape(-1,28,28,1)
x_test = x_test.reshape(-1,28,28,1)
"""
CNN modeli paramtre olarak

genişlik
yükseklik
kanal boyut bekler bunları atıyoruz

MNIST siyah-beyaz kanal=1
"""


y_train = to_categorical(y_train,10)
y_test= to_categorical(y_test, 10)
#etiketleri one-hot encode yapma

#CNN MODELİNİ OLUŞTURMA

model = Sequential()
#model katman katman oluşcak

model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))
#1. katman 32 filtre,3x3 boyutunda, aktivasyon fonksiyonu ise relu

model.add(MaxPooling2D(pool_size=(2,2)))
#2.katman Maxpooling ile görüntüüuü 2x2 lik alanda küçültme

model.add(Conv2D(64, kernel_size=(3,3),activation='relu'))
#3. katman 64 filtreli başka bir convulation

model.add(MaxPooling2D(pool_size=(2, 2)))
#4. katman tekrara maxpooling uygulama

model.add(Flatten())
#2D veriyi 1D halline getirir(yoğun katmana hazırlık)

model.add(Dense(128, activation='relu'))
#Dense(Tam Bağlantılı ) katman 12 nörün aktivasyon ReLU

model.add(Dense(10, activation='softmax'))
#çıkış katmanı 10 sınıf(0-9 rakamları için) softmax ile olasılık verilir

#MODELİN DERLENMESİ

#model derlemede optimzier,loss fonksiyonları ve başarı metriği tanımlanır
model.compile(
    optimizer='adam',  # ağırlıkları optimize eder
    loss='categorical_crossentropy', # Öok sınıflı sınıflandırma için uygun
    metrics=['accuracy'] # Doğruluk oranını ölçer
)

#MODEL EĞİTMİ

model.fit(x_train, y_train, epochs=5, batch_size=128, validation_data=(x_test, y_test))

#Modeli eğitme 5 apıchs boyunca her seferinde 128 veri ile eğitilcek

model.save("el_yazisi_modeli.h5")
print("Model başarıyla kaydedildi")

from google.colab import files
files.download("el_yazisi_modeli.h5")
#modeli indirme